{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import configparser\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_dir = os.path.join(os.getcwd(), '..')\n",
    "src_dir = os.path.join(setup_dir, 'src')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from d01_data.collect_video_data import collect_video_data\n",
    "from d01_data.collect_tims_data import get_tims_data_and_upload_to_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials\n",
    "config = configparser.ConfigParser()\n",
    "config.read(os.path.join(setup_dir, 'conf', 'local', 'credentials.yml'))\n",
    "config.read(os.path.join(setup_dir, 'conf', 'base', 'parameters.yml'))\n",
    "\n",
    "# local data folder\n",
    "video_dir = os.path.join(setup_dir, 'data', '01_raw', 'video_data')\n",
    "tims_dir = os.path.join(setup_dir, 'data', '01_raw', 'tims')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# videos\n",
    "collect_video_data(local_video_dir=video_dir,\n",
    "                   camera_list=ast.literal_eval(config.get('DATA_COLLECTION','camera_list')), \n",
    "                   website = ast.literal_eval(config.get('DATA_COLLECTION', 'jam_cam_website'))\n",
    "                   num_iterations = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maren_eckhoff/my_files/projects/dssg/teaching/project_directory/air_pollution_estimation/notebooks/../src/d01_data/collect_tims_data.py:14: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 14 of the file /Users/maren_eckhoff/my_files/projects/dssg/teaching/project_directory/air_pollution_estimation/notebooks/../src/d01_data/collect_tims_data.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(data)\n"
     ]
    }
   ],
   "source": [
    "get_tims_data_and_upload_to_s3(local_tims_dir = tims_dir,\n",
    "                              file_website = ast.literal_eval(config.get('DATA_COLLECTION', 'tims_file_website')),\n",
    "                              download_website = ast.literal_eval(config.get('DATA_COLLECTION', 'tims_download_website')))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "import datetime\n",
    "import requests\n",
    "import time\n",
    "import sys\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_finder_website = 'https://s3-eu-west-1.amazonaws.com/roads.data.tfl.gov.uk'\n",
    "r  = requests.get(file_finder_website)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3-eu-west-1.amazonaws.com/roads.data.tfl.gov.uk'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(config.get('DATA_COLLECTION', 'tims_file_website'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air-quality",
   "language": "python",
   "name": "air-quality"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
